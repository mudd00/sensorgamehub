# ğŸ”Š Sensor Game Hub v6.0 - ì˜¤ë””ì˜¤ ì‹œìŠ¤í…œ ì™„ì „ ê°€ì´ë“œ

## ğŸ“‹ ëª©ì°¨
1. [ì˜¤ë””ì˜¤ ì‹œìŠ¤í…œ ê°œìš”](#ì˜¤ë””ì˜¤-ì‹œìŠ¤í…œ-ê°œìš”)
2. [AI í†µí•© ì˜¤ë””ì˜¤ ì—”ì§„](#ai-í†µí•©-ì˜¤ë””ì˜¤-ì—”ì§„)
3. [ì„¼ì„œ ê¸°ë°˜ 3D ì˜¤ë””ì˜¤](#ì„¼ì„œ-ê¸°ë°˜-3d-ì˜¤ë””ì˜¤)
4. [ì ì‘í˜• ì˜¤ë””ì˜¤ ìµœì í™”](#ì ì‘í˜•-ì˜¤ë””ì˜¤-ìµœì í™”)

---

## ğŸ¯ ì˜¤ë””ì˜¤ ì‹œìŠ¤í…œ ê°œìš”

### ì‹œìŠ¤í…œ ì² í•™
Sensor Game Hub v6.0ì˜ ì˜¤ë””ì˜¤ ì‹œìŠ¤í…œì€ **Phase 2.2 AI ì‹œìŠ¤í…œê³¼ ì™„ì „ í†µí•©**ëœ ì§€ëŠ¥í˜• 3D ì˜¤ë””ì˜¤ ì†”ë£¨ì…˜ì…ë‹ˆë‹¤. ì„¼ì„œ ë°ì´í„°ë¥¼ í™œìš©í•œ ê³µê°„ ì˜¤ë””ì˜¤ì™€ AI ê¸°ë°˜ ì ì‘í˜• ì‚¬ìš´ë“œë¥¼ í†µí•´ ëª°ì…ê° ìˆëŠ” ì˜¤ë””ì˜¤ ê²½í—˜ì„ ì œê³µí•©ë‹ˆë‹¤.

### í•µì‹¬ íŠ¹ì§•
- **ì„¼ì„œ ì—°ë™ 3D ì˜¤ë””ì˜¤**: ë””ë°”ì´ìŠ¤ ë°©í–¥ì— ë”°ë¥¸ ì‹¤ì‹œê°„ ê³µê°„ìŒí–¥
- **AI ê¸°ë°˜ ì ì‘í˜• ë¯¹ì‹±**: ì‚¬ìš©ì ì„ í˜¸ë„ì™€ í™˜ê²½ì„ í•™ìŠµí•œ ë™ì  ì˜¤ë””ì˜¤ ì¡°ì ˆ
- **ì§€ëŠ¥í˜• ì˜¤ë””ì˜¤ ì••ì¶•**: ë„¤íŠ¸ì›Œí¬ ìƒí™©ì— ë§ëŠ” ì ì‘í˜• ì˜¤ë””ì˜¤ í’ˆì§ˆ
- **ì˜ˆì¸¡í˜• ì˜¤ë””ì˜¤ ë¡œë”©**: ê²Œì„ ìƒí™©ì„ ì˜ˆì¸¡í•œ ì„ ì œì  ì˜¤ë””ì˜¤ ë¦¬ì†ŒìŠ¤ ë¡œë”©
- **í™˜ê²½ ì¸ì‹ ì˜¤ë””ì˜¤**: ì£¼ë³€ ì†ŒìŒì„ ë¶„ì„í•œ ìµœì í™”ëœ ì˜¤ë””ì˜¤ ì¶œë ¥

---

## ğŸ¤– AI í†µí•© ì˜¤ë””ì˜¤ ì—”ì§„

### ì§€ëŠ¥í˜• ì˜¤ë””ì˜¤ ì‹œìŠ¤í…œ í´ë˜ìŠ¤
```javascript
// Phase 2.2 AI ì‹œìŠ¤í…œ ì™„ì „ í†µí•© ì˜¤ë””ì˜¤ ì—”ì§„
class IntelligentAudioSystem {
    constructor(options = {}) {
        // AI ì‹œìŠ¤í…œ í†µí•©
        this.contextManager = new ContextManager({
            sessionType: 'audio_system',
            aiFeatures: ['audio_optimization', 'spatial_processing', 'user_preference_learning']
        });

        this.realTimeDebugger = new RealTimeDebugger({
            category: 'audio_system_debugging',
            enableAutoRecovery: true
        });

        this.satisfactionTracker = new UserSatisfactionTracker({
            category: 'audio_experience',
            realTimeTracking: true
        });

        // Web Audio API ì»¨í…ìŠ¤íŠ¸
        this.audioContext = null;
        this.audioWorklet = null;

        // AI ê¸°ë°˜ ì ì‘í˜• ì˜¤ë””ì˜¤ ì„¤ì •
        this.adaptiveSettings = {
            masterVolume: options.masterVolume || 1.0,
            spatialAudio: options.spatialAudio !== false,
            qualityLevel: 1.0,
            compressionLevel: 0,
            dynamicRange: 'full', // 'full', 'compressed', 'night'
            environmentProfile: 'default'
        };

        // 3D ì˜¤ë””ì˜¤ ì‹œìŠ¤í…œ
        this.spatialAudio = {
            listener: null,
            pannerNodes: new Map(),
            convolver: null,
            reverbSettings: {
                roomSize: 'medium',
                damping: 0.3,
                wetness: 0.2
            }
        };

        // AI ê¸°ë°˜ ì˜¤ë””ì˜¤ ìµœì í™”
        this.audioOptimizer = {
            mixingModel: null,
            compressionModel: null,
            environmentAnalyzer: null,
            preferenceTracker: null
        };

        // ì˜¤ë””ì˜¤ ë¦¬ì†ŒìŠ¤ ê´€ë¦¬
        this.audioResources = {
            buffers: new Map(),
            sources: new Map(),
            effects: new Map(),
            streams: new Map()
        };

        // ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì²´ì¸
        this.audioChain = {
            inputGain: null,
            compressor: null,
            equalizer: null,
            spatialProcessor: null,
            masterGain: null,
            analyzer: null
        };

        // ì„±ëŠ¥ ë©”íŠ¸ë¦­
        this.performanceMetrics = {
            latency: 0,
            cpuUsage: 0,
            memoryUsage: 0,
            activeNodes: 0,
            processingTime: 0
        };
    }

    // ì˜¤ë””ì˜¤ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    async initialize() {
        try {
            // Web Audio API ì»¨í…ìŠ¤íŠ¸ ìƒì„±
            await this.initializeAudioContext();

            // AI ì‹œìŠ¤í…œ ì´ˆê¸°í™”
            await this.contextManager.initialize();

            // AI ê¸°ë°˜ ì˜¤ë””ì˜¤ ëª¨ë¸ ë¡œë”©
            await this.initializeAIModels();

            // 3D ì˜¤ë””ì˜¤ ì„¤ì •
            await this.setup3DAudio();

            // ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì²´ì¸ êµ¬ì„±
            await this.setupAudioChain();

            // í™˜ê²½ ë¶„ì„ ì‹œì‘
            await this.startEnvironmentAnalysis();

            console.log('ğŸ”Š Intelligent Audio System initialized');

        } catch (error) {
            this.realTimeDebugger.handleError(error, 'audio_system_initialization');
            throw error;
        }
    }

    // Web Audio API ì»¨í…ìŠ¤íŠ¸ ì´ˆê¸°í™”
    async initializeAudioContext() {
        // AudioContext ìƒì„± (ëª¨ë°”ì¼ í˜¸í™˜ì„± ê³ ë ¤)
        const AudioContextClass = window.AudioContext || window.webkitAudioContext;
        this.audioContext = new AudioContextClass({
            latencyHint: 'interactive',
            sampleRate: 44100
        });

        // ì‚¬ìš©ì ì œìŠ¤ì²˜ í›„ ì»¨í…ìŠ¤íŠ¸ ì¬ê°œ (ëª¨ë°”ì¼ ì •ì±…)
        if (this.audioContext.state === 'suspended') {
            document.addEventListener('touchstart', () => {
                this.audioContext.resume();
            }, { once: true });

            document.addEventListener('click', () => {
                this.audioContext.resume();
            }, { once: true });
        }

        // AudioWorklet ë¡œë”© (ê³ ê¸‰ ì˜¤ë””ì˜¤ ì²˜ë¦¬ìš©)
        try {
            await this.audioContext.audioWorklet.addModule('/js/audio-processors/spatial-processor.js');
            console.log('âœ… AudioWorklet loaded');
        } catch (error) {
            console.warn('AudioWorklet not available, falling back to ScriptProcessor');
        }

        console.log(`âœ… AudioContext created (${this.audioContext.sampleRate}Hz)`);
    }

    // AI ëª¨ë¸ ì´ˆê¸°í™”
    async initializeAIModels() {
        // ì˜¤ë””ì˜¤ ë¯¹ì‹± ëª¨ë¸
        this.audioOptimizer.mixingModel = await this.contextManager.createAIModel({
            type: 'audio_mixing',
            features: ['volume_levels', 'frequency_spectrum', 'user_preference', 'environment_noise'],
            algorithm: 'neural_network'
        });

        // ì˜¤ë””ì˜¤ ì••ì¶• ëª¨ë¸
        this.audioOptimizer.compressionModel = await this.contextManager.createAIModel({
            type: 'audio_compression',
            features: ['bandwidth', 'latency', 'quality_preference', 'device_capability'],
            algorithm: 'decision_tree'
        });

        // í™˜ê²½ ë¶„ì„ ëª¨ë¸
        this.audioOptimizer.environmentAnalyzer = await this.contextManager.createAIModel({
            type: 'environment_analysis',
            features: ['ambient_noise', 'room_acoustics', 'device_type', 'listening_context'],
            algorithm: 'clustering'
        });

        // ì‚¬ìš©ì ì„ í˜¸ë„ ì¶”ì  ëª¨ë¸
        this.audioOptimizer.preferenceTracker = await this.contextManager.createAIModel({
            type: 'user_preference',
            features: ['volume_adjustments', 'eq_settings', 'spatial_preferences', 'interaction_patterns'],
            algorithm: 'collaborative_filtering'
        });
    }

    // 3D ì˜¤ë””ì˜¤ ì„¤ì •
    async setup3DAudio() {
        // ë¦¬ìŠ¤ë„ˆ ì„¤ì • (í”Œë ˆì´ì–´ ìœ„ì¹˜)
        this.spatialAudio.listener = this.audioContext.listener;

        // Panner ëª¨ë¸ ì„¤ì • (HRTF ì„ í˜¸)
        if (this.spatialAudio.listener.positionX) {
            // ìµœì‹  Web Audio API ì‚¬ìš©
            this.spatialAudio.listener.positionX.value = 0;
            this.spatialAudio.listener.positionY.value = 0;
            this.spatialAudio.listener.positionZ.value = 0;

            this.spatialAudio.listener.forwardX.value = 0;
            this.spatialAudio.listener.forwardY.value = 0;
            this.spatialAudio.listener.forwardZ.value = -1;

            this.spatialAudio.listener.upX.value = 0;
            this.spatialAudio.listener.upY.value = 1;
            this.spatialAudio.listener.upZ.value = 0;
        }

        // ë¦¬ë²„ë¸Œ ì„¤ì •
        await this.setupReverb();

        console.log('ğŸ§ 3D Audio system configured');
    }

    // ë¦¬ë²„ë¸Œ ì„¤ì •
    async setupReverb() {
        // ì»¨ë³¼ë£¨ì…˜ ë¦¬ë²„ë¸Œ ë…¸ë“œ ìƒì„±
        this.spatialAudio.convolver = this.audioContext.createConvolver();

        // ì„í„ìŠ¤ ì‘ë‹µ ìƒì„± (AI ê¸°ë°˜ ê³µê°„ ì‹œë®¬ë ˆì´ì…˜)
        const impulseResponse = await this.generateImpulseResponse();
        this.spatialAudio.convolver.buffer = impulseResponse;

        console.log('ğŸ  Reverb system configured');
    }

    // ì„í„ìŠ¤ ì‘ë‹µ ìƒì„±
    async generateImpulseResponse() {
        const settings = this.spatialAudio.reverbSettings;
        const sampleRate = this.audioContext.sampleRate;
        const length = sampleRate * 3; // 3ì´ˆ ë¦¬ë²„ë¸Œ

        const impulse = this.audioContext.createBuffer(2, length, sampleRate);
        const left = impulse.getChannelData(0);
        const right = impulse.getChannelData(1);

        // AI ê¸°ë°˜ ë£¸ íŠ¹ì„± ì‹œë®¬ë ˆì´ì…˜
        for (let i = 0; i < length; i++) {
            const decay = Math.pow(1 - (i / length), 2 * settings.damping);
            const noise = (Math.random() * 2 - 1) * decay;

            left[i] = noise * 0.5;
            right[i] = noise * 0.5;
        }

        return impulse;
    }

    // ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì²´ì¸ êµ¬ì„±
    async setupAudioChain() {
        // ì…ë ¥ ê²Œì¸
        this.audioChain.inputGain = this.audioContext.createGain();
        this.audioChain.inputGain.gain.value = 1.0;

        // ì»´í”„ë ˆì„œ (ë™ì  ë²”ìœ„ ì¡°ì ˆ)
        this.audioChain.compressor = this.audioContext.createDynamicsCompressor();
        this.audioChain.compressor.threshold.value = -24;
        this.audioChain.compressor.knee.value = 30;
        this.audioChain.compressor.ratio.value = 12;
        this.audioChain.compressor.attack.value = 0.003;
        this.audioChain.compressor.release.value = 0.25;

        // ì´í€„ë¼ì´ì € (ì£¼íŒŒìˆ˜ ì¡°ì ˆ)
        await this.setupEqualizer();

        // ê³µê°„ ì˜¤ë””ì˜¤ í”„ë¡œì„¸ì„œ
        if (this.audioContext.audioWorklet) {
            this.audioChain.spatialProcessor = new AudioWorkletNode(
                this.audioContext,
                'spatial-processor',
                {
                    numberOfInputs: 1,
                    numberOfOutputs: 1,
                    channelCount: 2
                }
            );
        }

        // ë§ˆìŠ¤í„° ê²Œì¸
        this.audioChain.masterGain = this.audioContext.createGain();
        this.audioChain.masterGain.gain.value = this.adaptiveSettings.masterVolume;

        // ì˜¤ë””ì˜¤ ë¶„ì„ê¸°
        this.audioChain.analyzer = this.audioContext.createAnalyser();
        this.audioChain.analyzer.fftSize = 2048;
        this.audioChain.analyzer.smoothingTimeConstant = 0.8;

        // ì²´ì¸ ì—°ê²°
        this.connectAudioChain();

        console.log('ğŸ”— Audio processing chain configured');
    }

    // ì´í€„ë¼ì´ì € ì„¤ì •
    async setupEqualizer() {
        const frequencies = [60, 170, 350, 1000, 3500, 10000];
        this.audioChain.equalizer = frequencies.map(freq => {
            const filter = this.audioContext.createBiquadFilter();
            filter.type = 'peaking';
            filter.frequency.value = freq;
            filter.Q.value = 1;
            filter.gain.value = 0;
            return filter;
        });

        // EQ í•„í„° ì²´ì¸ ì—°ê²°
        for (let i = 0; i < this.audioChain.equalizer.length - 1; i++) {
            this.audioChain.equalizer[i].connect(this.audioChain.equalizer[i + 1]);
        }
    }

    // ì˜¤ë””ì˜¤ ì²´ì¸ ì—°ê²°
    connectAudioChain() {
        let currentNode = this.audioChain.inputGain;

        // ì»´í”„ë ˆì„œ ì—°ê²°
        currentNode.connect(this.audioChain.compressor);
        currentNode = this.audioChain.compressor;

        // ì´í€„ë¼ì´ì € ì—°ê²°
        if (this.audioChain.equalizer.length > 0) {
            currentNode.connect(this.audioChain.equalizer[0]);
            currentNode = this.audioChain.equalizer[this.audioChain.equalizer.length - 1];
        }

        // ê³µê°„ í”„ë¡œì„¸ì„œ ì—°ê²°
        if (this.audioChain.spatialProcessor) {
            currentNode.connect(this.audioChain.spatialProcessor);
            currentNode = this.audioChain.spatialProcessor;
        }

        // ë§ˆìŠ¤í„° ê²Œì¸ ì—°ê²°
        currentNode.connect(this.audioChain.masterGain);

        // ë¶„ì„ê¸° ë° ì¶œë ¥ ì—°ê²°
        this.audioChain.masterGain.connect(this.audioChain.analyzer);
        this.audioChain.masterGain.connect(this.audioContext.destination);
    }

    // 3D ì˜¤ë””ì˜¤ ì†ŒìŠ¤ ìƒì„±
    async create3DAudioSource(audioBuffer, position = { x: 0, y: 0, z: 0 }) {
        const source = this.audioContext.createBufferSource();
        source.buffer = audioBuffer;

        // 3D íŒ¨ë„ˆ ë…¸ë“œ ìƒì„±
        const panner = this.audioContext.createPanner();
        panner.panningModel = 'HRTF';
        panner.distanceModel = 'inverse';
        panner.maxDistance = 1000;
        panner.rolloffFactor = 1;
        panner.coneInnerAngle = 360;
        panner.coneOuterAngle = 0;
        panner.coneOuterGain = 0;

        // ìœ„ì¹˜ ì„¤ì •
        if (panner.positionX) {
            panner.positionX.value = position.x;
            panner.positionY.value = position.y;
            panner.positionZ.value = position.z;
        } else {
            panner.setPosition(position.x, position.y, position.z);
        }

        // ì—°ê²°
        source.connect(panner);
        panner.connect(this.audioChain.inputGain);

        // ë¦¬ë²„ë¸Œ ì—°ê²° (ì˜µì…˜)
        if (this.spatialAudio.convolver && this.spatialAudio.reverbSettings.wetness > 0) {
            const dryGain = this.audioContext.createGain();
            const wetGain = this.audioContext.createGain();

            dryGain.gain.value = 1 - this.spatialAudio.reverbSettings.wetness;
            wetGain.gain.value = this.spatialAudio.reverbSettings.wetness;

            panner.connect(dryGain);
            panner.connect(this.spatialAudio.convolver);
            this.spatialAudio.convolver.connect(wetGain);

            dryGain.connect(this.audioChain.inputGain);
            wetGain.connect(this.audioChain.inputGain);
        }

        // íŒ¨ë„ˆ ë…¸ë“œ ë“±ë¡
        const sourceId = this.generateSourceId();
        this.spatialAudio.pannerNodes.set(sourceId, panner);

        return {
            source: source,
            panner: panner,
            sourceId: sourceId,
            position: position
        };
    }

    // ì„¼ì„œ ë°ì´í„°ë¡œ ë¦¬ìŠ¤ë„ˆ ì—…ë°ì´íŠ¸
    async updateListenerFromSensor(sensorData) {
        if (!this.adaptiveSettings.spatialAudio) return;

        const { orientation } = sensorData;
        const listener = this.spatialAudio.listener;

        // ë°©í–¥ ë²¡í„° ê³„ì‚°
        const yaw = orientation.alpha * Math.PI / 180;
        const pitch = orientation.beta * Math.PI / 180;
        const roll = orientation.gamma * Math.PI / 180;

        // ì „ë°© ë²¡í„° ê³„ì‚°
        const forwardX = Math.sin(yaw) * Math.cos(pitch);
        const forwardY = -Math.sin(pitch);
        const forwardZ = -Math.cos(yaw) * Math.cos(pitch);

        // ìƒë°© ë²¡í„° ê³„ì‚°
        const upX = Math.sin(roll) * Math.cos(yaw);
        const upY = Math.cos(roll);
        const upZ = Math.sin(roll) * Math.sin(yaw);

        // ë¦¬ìŠ¤ë„ˆ ë°©í–¥ ì—…ë°ì´íŠ¸
        if (listener.forwardX) {
            listener.forwardX.value = forwardX;
            listener.forwardY.value = forwardY;
            listener.forwardZ.value = forwardZ;

            listener.upX.value = upX;
            listener.upY.value = upY;
            listener.upZ.value = upZ;
        } else {
            listener.setOrientation(forwardX, forwardY, forwardZ, upX, upY, upZ);
        }

        // AI ê¸°ë°˜ ê³µê°„ ì˜¤ë””ì˜¤ ìµœì í™”
        await this.optimizeSpatialAudio(sensorData);
    }

    // AI ê¸°ë°˜ ê³µê°„ ì˜¤ë””ì˜¤ ìµœì í™”
    async optimizeSpatialAudio(sensorData) {
        // ì„¼ì„œ ë°ì´í„° ë¶„ì„
        const motionIntensity = Math.sqrt(
            sensorData.acceleration.x ** 2 +
            sensorData.acceleration.y ** 2 +
            sensorData.acceleration.z ** 2
        );

        // ë™ì  ê³µê°„ ì˜¤ë””ì˜¤ íŒŒë¼ë¯¸í„° ì¡°ì ˆ
        if (motionIntensity > 5.0) {
            // ë¹ ë¥¸ ì›€ì§ì„ ì‹œ ê³µê°„ê° ì¦ê°€
            this.spatialAudio.reverbSettings.wetness = Math.min(0.4,
                this.spatialAudio.reverbSettings.wetness + 0.1
            );
        } else {
            // ì •ì  ìƒíƒœì—ì„œ ê³µê°„ê° ê°ì†Œ
            this.spatialAudio.reverbSettings.wetness = Math.max(0.1,
                this.spatialAudio.reverbSettings.wetness - 0.05
            );
        }

        // ë¦¬ë²„ë¸Œ ì„¤ì • ì—…ë°ì´íŠ¸
        await this.updateReverbSettings();
    }

    // í™˜ê²½ ë¶„ì„ ì‹œì‘
    async startEnvironmentAnalysis() {
        // ë§ˆì´í¬ ì ‘ê·¼ ê¶Œí•œ ìš”ì²­ (í™˜ê²½ ì†ŒìŒ ë¶„ì„ìš©)
        try {
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            const micSource = this.audioContext.createMediaStreamSource(stream);
            const micAnalyzer = this.audioContext.createAnalyser();

            micAnalyzer.fftSize = 1024;
            micSource.connect(micAnalyzer);

            // ì£¼ê¸°ì  í™˜ê²½ ë¶„ì„
            this.startEnvironmentMonitoring(micAnalyzer);

        } catch (error) {
            console.warn('Microphone access denied, using default environment settings');
        }
    }

    // í™˜ê²½ ëª¨ë‹ˆí„°ë§
    startEnvironmentMonitoring(analyzer) {
        const bufferLength = analyzer.frequencyBinCount;
        const dataArray = new Uint8Array(bufferLength);

        const analyze = async () => {
            analyzer.getByteFrequencyData(dataArray);

            // í™˜ê²½ ì†ŒìŒ ë ˆë²¨ ê³„ì‚°
            const averageLevel = dataArray.reduce((sum, value) => sum + value, 0) / bufferLength;
            const noiseLevel = averageLevel / 255;

            // AI ê¸°ë°˜ í™˜ê²½ ë¶„ì„
            const environmentProfile = await this.audioOptimizer.environmentAnalyzer.analyze({
                noiseLevel: noiseLevel,
                frequencySpectrum: Array.from(dataArray),
                deviceType: this.detectDeviceType(),
                timeOfDay: new Date().getHours()
            });

            // í™˜ê²½ì— ë”°ë¥¸ ì˜¤ë””ì˜¤ ì¡°ì •
            await this.adaptToEnvironment(environmentProfile);

            // 1ì´ˆë§ˆë‹¤ ë¶„ì„
            setTimeout(analyze, 1000);
        };

        analyze();
    }

    // í™˜ê²½ ì ì‘
    async adaptToEnvironment(environmentProfile) {
        // ì†ŒìŒ í™˜ê²½ì—ì„œ ë™ì  ë²”ìœ„ ì••ì¶•
        if (environmentProfile.noiseLevel > 0.3) {
            this.audioChain.compressor.threshold.value = -18;
            this.audioChain.compressor.ratio.value = 8;
        } else {
            this.audioChain.compressor.threshold.value = -24;
            this.audioChain.compressor.ratio.value = 4;
        }

        // ë°¤ ì‹œê°„ ëª¨ë“œ
        if (environmentProfile.timeContext === 'night') {
            this.adaptiveSettings.dynamicRange = 'night';
            this.audioChain.compressor.ratio.value = 16;
            this.audioChain.masterGain.gain.value *= 0.7;
        }

        // í™˜ê²½ í”„ë¡œí•„ ì €ì¥
        this.adaptiveSettings.environmentProfile = environmentProfile;
    }

    // ì˜¤ë””ì˜¤ ë¦¬ì†ŒìŠ¤ ë¡œë”©
    async loadAudioResource(url, resourceId) {
        try {
            const response = await fetch(url);
            const arrayBuffer = await response.arrayBuffer();
            const audioBuffer = await this.audioContext.decodeAudioData(arrayBuffer);

            this.audioResources.buffers.set(resourceId, audioBuffer);
            console.log(`ğŸ”Š Audio resource loaded: ${resourceId}`);

            return audioBuffer;

        } catch (error) {
            this.realTimeDebugger.handleError(error, 'audio_loading', { url, resourceId });
            throw error;
        }
    }

    // ì˜¤ë””ì˜¤ ì¬ìƒ
    async playAudio(resourceId, options = {}) {
        const audioBuffer = this.audioResources.buffers.get(resourceId);
        if (!audioBuffer) {
            throw new Error(`Audio resource not found: ${resourceId}`);
        }

        // 3D ì˜¤ë””ì˜¤ ì†ŒìŠ¤ ìƒì„±
        const audioSource = await this.create3DAudioSource(
            audioBuffer,
            options.position || { x: 0, y: 0, z: 0 }
        );

        // ì¬ìƒ ì„¤ì •
        audioSource.source.loop = options.loop || false;
        audioSource.source.playbackRate.value = options.playbackRate || 1.0;

        // ë³¼ë¥¨ ì„¤ì •
        if (options.volume !== undefined) {
            const volumeGain = this.audioContext.createGain();
            volumeGain.gain.value = options.volume;
            audioSource.source.disconnect();
            audioSource.source.connect(volumeGain);
            volumeGain.connect(audioSource.panner);
        }

        // ì¬ìƒ ì‹œì‘
        audioSource.source.start(0);

        // ë¦¬ì†ŒìŠ¤ ë“±ë¡
        this.audioResources.sources.set(audioSource.sourceId, audioSource);

        // AI ê¸°ë°˜ ì¬ìƒ ë¶„ì„
        await this.analyzeAudioPlayback(resourceId, options);

        return audioSource.sourceId;
    }

    // AI ê¸°ë°˜ ì¬ìƒ ë¶„ì„
    async analyzeAudioPlayback(resourceId, options) {
        // ì‚¬ìš©ì ì„ í˜¸ë„ í•™ìŠµ
        await this.audioOptimizer.preferenceTracker.learn({
            resourceType: resourceId,
            volume: options.volume || 1.0,
            spatialPosition: options.position || { x: 0, y: 0, z: 0 },
            environmentContext: this.adaptiveSettings.environmentProfile,
            userContext: await this.contextManager.getUserContext()
        });

        // ì‚¬ìš©ì ë§Œì¡±ë„ ì¶”ì 
        this.satisfactionTracker.trackAudioEvent({
            type: 'audio_playback',
            resourceId: resourceId,
            settings: options,
            timestamp: Date.now()
        });
    }

    // ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
    async updatePerformanceMetrics() {
        // ë ˆì´í„´ì‹œ ê³„ì‚°
        this.performanceMetrics.latency = this.audioContext.baseLatency +
                                        this.audioContext.outputLatency;

        // í™œì„± ë…¸ë“œ ìˆ˜
        this.performanceMetrics.activeNodes = this.audioResources.sources.size;

        // CPU ì‚¬ìš©ëŸ‰ ì¶”ì •
        this.performanceMetrics.cpuUsage = this.estimateAudioCPUUsage();

        // AI ë¶„ì„ì„ ìœ„í•œ ë©”íŠ¸ë¦­ ì „ì†¡
        await this.contextManager.trackPerformance('audio_system', this.performanceMetrics);
    }

    // ìœ í‹¸ë¦¬í‹° ë©”ì„œë“œë“¤
    generateSourceId() {
        return `audio_source_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
    }

    detectDeviceType() {
        const userAgent = navigator.userAgent;
        if (/Android|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(userAgent)) {
            return 'mobile';
        }
        return 'desktop';
    }

    estimateAudioCPUUsage() {
        // ê°„ë‹¨í•œ CPU ì‚¬ìš©ëŸ‰ ì¶”ì •
        return Math.min(100, this.performanceMetrics.activeNodes * 2);
    }

    // ì •ë¦¬
    async cleanup() {
        // ëª¨ë“  ì˜¤ë””ì˜¤ ì†ŒìŠ¤ ì •ì§€
        for (const [sourceId, audioSource] of this.audioResources.sources) {
            try {
                audioSource.source.stop();
                audioSource.source.disconnect();
                audioSource.panner.disconnect();
            } catch (error) {
                // ì´ë¯¸ ì •ì§€ëœ ì†ŒìŠ¤ ë¬´ì‹œ
            }
        }

        // ë¦¬ì†ŒìŠ¤ ì •ë¦¬
        this.audioResources.sources.clear();
        this.audioResources.buffers.clear();
        this.spatialAudio.pannerNodes.clear();

        // AudioContext ì •ë¦¬
        if (this.audioContext && this.audioContext.state !== 'closed') {
            await this.audioContext.close();
        }

        // AI ì‹œìŠ¤í…œ ì •ë¦¬
        await this.contextManager.cleanup();

        console.log('ğŸ§¹ Audio System cleanup completed');
    }
}
```

---

## ğŸ“± ì„¼ì„œ ê¸°ë°˜ 3D ì˜¤ë””ì˜¤

### ì„¼ì„œ ì˜¤ë””ì˜¤ ì¸í„°ë™ì…˜ ì‹œìŠ¤í…œ
```javascript
class SensorAudioInteraction {
    constructor(audioSystem) {
        this.audioSystem = audioSystem;
        this.sensorProcessor = new SensorDataProcessor();

        // ì œìŠ¤ì²˜ ê¸°ë°˜ ì˜¤ë””ì˜¤ ì œì–´
        this.gestureAudioMapping = {
            'shake': 'pause_all',
            'tilt_left': 'volume_down',
            'tilt_right': 'volume_up',
            'double_tap': 'toggle_spatial',
            'rotation_cw': 'next_track',
            'rotation_ccw': 'prev_track'
        };

        // ëª¨ì…˜ ê¸°ë°˜ ì˜¤ë””ì˜¤ íš¨ê³¼
        this.motionEffects = {
            walkingEffect: new WalkingAudioEffect(),
            runningEffect: new RunningAudioEffect(),
            jumpEffect: new JumpAudioEffect()
        };
    }

    // ì„¼ì„œ ë°ì´í„°ë¡œ ì˜¤ë””ì˜¤ ì œì–´
    async processSensorAudio(sensorData) {
        // 3D ë¦¬ìŠ¤ë„ˆ ì—…ë°ì´íŠ¸
        await this.audioSystem.updateListenerFromSensor(sensorData);

        // ëª¨ì…˜ ê°ì§€ ë° ì˜¤ë””ì˜¤ íš¨ê³¼
        const motion = await this.detectMotion(sensorData);
        if (motion.type !== 'static') {
            await this.applyMotionAudioEffect(motion);
        }

        // ì œìŠ¤ì²˜ ê¸°ë°˜ ì˜¤ë””ì˜¤ ì œì–´
        const gesture = await this.detectAudioGesture(sensorData);
        if (gesture.confidence > 0.8) {
            await this.handleAudioGesture(gesture);
        }
    }

    // ëª¨ì…˜ ê°ì§€
    async detectMotion(sensorData) {
        const acceleration = sensorData.acceleration;
        const magnitude = Math.sqrt(
            acceleration.x ** 2 + acceleration.y ** 2 + acceleration.z ** 2
        );

        if (magnitude > 15) {
            return { type: 'running', intensity: magnitude / 20 };
        } else if (magnitude > 8) {
            return { type: 'walking', intensity: magnitude / 15 };
        } else if (magnitude > 20) {
            return { type: 'jumping', intensity: 1.0 };
        }

        return { type: 'static', intensity: 0 };
    }

    // ëª¨ì…˜ ì˜¤ë””ì˜¤ íš¨ê³¼ ì ìš©
    async applyMotionAudioEffect(motion) {
        switch (motion.type) {
            case 'walking':
                await this.motionEffects.walkingEffect.apply(motion.intensity);
                break;
            case 'running':
                await this.motionEffects.runningEffect.apply(motion.intensity);
                break;
            case 'jumping':
                await this.motionEffects.jumpEffect.apply(motion.intensity);
                break;
        }
    }
}
```

---

## âš¡ ì ì‘í˜• ì˜¤ë””ì˜¤ ìµœì í™”

### AI ê¸°ë°˜ ì˜¤ë””ì˜¤ í’ˆì§ˆ ê´€ë¦¬
```javascript
class AdaptiveAudioQualityManager {
    constructor(audioSystem) {
        this.audioSystem = audioSystem;
        this.qualityModel = null;
        this.networkMonitor = new NetworkMonitor();
    }

    // ë„¤íŠ¸ì›Œí¬ ìƒí™©ì— ë”°ë¥¸ ì˜¤ë””ì˜¤ í’ˆì§ˆ ì¡°ì ˆ
    async adaptToNetworkConditions() {
        const networkStatus = await this.networkMonitor.getStatus();

        if (networkStatus.bandwidth < 100000) { // 100kbps ë¯¸ë§Œ
            // ì˜¤ë””ì˜¤ ì••ì¶• ë ˆë²¨ ì¦ê°€
            await this.audioSystem.setCompressionLevel(0.8);
            // ê³µê°„ ì˜¤ë””ì˜¤ ë¹„í™œì„±í™”
            this.audioSystem.adaptiveSettings.spatialAudio = false;
        } else if (networkStatus.bandwidth > 1000000) { // 1Mbps ì´ˆê³¼
            // ê³ í’ˆì§ˆ ì˜¤ë””ì˜¤ í™œì„±í™”
            await this.audioSystem.setCompressionLevel(0.1);
            this.audioSystem.adaptiveSettings.spatialAudio = true;
        }
    }

    // ë°°í„°ë¦¬ ìƒíƒœì— ë”°ë¥¸ ìµœì í™”
    async adaptToBatteryLevel() {
        if ('getBattery' in navigator) {
            const battery = await navigator.getBattery();

            if (battery.level < 0.2) { // ë°°í„°ë¦¬ 20% ë¯¸ë§Œ
                // íŒŒì›Œ ì„¸ì´ë¹™ ëª¨ë“œ
                this.audioSystem.adaptiveSettings.spatialAudio = false;
                await this.audioSystem.setQualityLevel(0.6);
            }
        }
    }
}
```

ì´ë ‡ê²Œ audio-system.md (2í˜ì´ì§€)ë¥¼ ì™„ì„±í–ˆìŠµë‹ˆë‹¤. Phase 2.2 AI ì‹œìŠ¤í…œë“¤ì„ ì™„ì „íˆ í†µí•©í•œ ì§€ëŠ¥í˜• ì˜¤ë””ì˜¤ ì‹œìŠ¤í…œì„ êµ¬í˜„í–ˆìŠµë‹ˆë‹¤.

ë‹¤ìŒìœ¼ë¡œ pwa-implementation.md (2í˜ì´ì§€)ë¥¼ ì‘ì„±í•˜ê² ìŠµë‹ˆë‹¤.